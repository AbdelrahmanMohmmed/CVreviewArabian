{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-27T22:28:49.318246Z",
     "iopub.status.busy": "2025-08-27T22:28:49.317396Z",
     "iopub.status.idle": "2025-08-27T22:29:36.503271Z",
     "shell.execute_reply": "2025-08-27T22:29:36.502518Z",
     "shell.execute_reply.started": "2025-08-27T22:28:49.318212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T22:29:36.505176Z",
     "iopub.status.busy": "2025-08-27T22:29:36.504581Z",
     "iopub.status.idle": "2025-08-27T22:29:36.511301Z",
     "shell.execute_reply": "2025-08-27T22:29:36.510527Z",
     "shell.execute_reply.started": "2025-08-27T22:29:36.505144Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161594, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('/home/jax/CVreviewArabian/data/preprocessed/sampled_cleaned.csv')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T22:31:00.119735Z",
     "iopub.status.busy": "2025-08-27T22:31:00.119418Z",
     "iopub.status.idle": "2025-08-27T22:31:00.126123Z",
     "shell.execute_reply": "2025-08-27T22:31:00.125036Z",
     "shell.execute_reply.started": "2025-08-27T22:31:00.119670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Experience', 'Qualifications', 'Salary Range',\n",
       "       'location', 'Country', 'latitude', 'longitude', 'Work Type',\n",
       "       'Company Size', 'Preference', 'Job Title', 'Role', 'Job Portal',\n",
       "       'Job Description', 'Benefits', 'skills', 'Responsibilities'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T22:55:31.883858Z",
     "iopub.status.busy": "2025-08-27T22:55:31.883480Z",
     "iopub.status.idle": "2025-08-27T22:55:32.590302Z",
     "shell.execute_reply": "2025-08-27T22:55:32.589387Z",
     "shell.execute_reply.started": "2025-08-27T22:55:31.883832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:34:06.219370Z",
     "iopub.status.busy": "2025-08-27T23:34:06.219003Z",
     "iopub.status.idle": "2025-08-27T23:34:06.225669Z",
     "shell.execute_reply": "2025-08-27T23:34:06.224610Z",
     "shell.execute_reply.started": "2025-08-27T23:34:06.219344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TESTING_SKILLS = [\n",
    "    'selenium', 'junit', 'testng', 'postman', 'jmeter', 'cypress', 'appium', \n",
    "    'loadrunner', 'qa', 'quality assurance', 'test automation', 'manual testing', \n",
    "    'regression testing', 'functional testing', 'performance testing', 'usability testing', \n",
    "    'api testing', 'cross-browser testing', 'mobile testing'\n",
    "]\n",
    "GENERAL_SKILLS = [\n",
    "    'python', 'java', 'javascript', 'sql', 'git', 'jenkins', 'docker', 'agile', \n",
    "    'scrum', 'problem solving', 'communication', 'jira', 'bugzilla','c++', \n",
    "    'software development', 'html', 'css'\n",
    "]\n",
    "SKILLS_LIST = TESTING_SKILLS + GENERAL_SKILLS\n",
    "\n",
    "# Role keywords for filtering relevant jobs\n",
    "TESTER_KEYWORDS = ['tester', 'qa', 'quality assurance', 'test engineer', 'software tester']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:26:15.243084Z",
     "iopub.status.busy": "2025-08-27T23:26:15.242665Z",
     "iopub.status.idle": "2025-08-27T23:26:15.250041Z",
     "shell.execute_reply": "2025-08-27T23:26:15.249044Z",
     "shell.execute_reply.started": "2025-08-27T23:26:15.243058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cv_text = \"\"\"\n",
    "SUMMARY\n",
    "Computing and Data Science undergraduate (Expected Graduation: 2026) specializing in Machine Learning and Data Analysis.\n",
    "Possesses hands-on experience developing predictive models, performing complex data preprocessing, feature engineering,\n",
    "and visualizing datasets through academic projects and extensive self-study. Proven ability to leverage Python, Scikit-learn,\n",
    "TensorFlow, and SQL to derive actionable insights and build data-driven solutions. Eager to apply analytical and technical skills\n",
    "to a challenging Junior Machine Learning Engineer role.\n",
    "EDUCATION\n",
    "B.Sc. in Computing and Data Science | Alexandria University, Alexandria, Egypt Expected Graduation: 2026 | GPA: 2.95\n",
    "●​●​●​●​Completed rigorous coursework covering algorithms, data structures, statistics, database management, and software\n",
    "engineering principles.\n",
    "Developed 4+ significant data science and machine learning projects, focusing on data analysis, model implementation,\n",
    "evaluation, and visualization.\n",
    "Applied software development best practices, achieving 85%+ project code coverage through comprehensive unit\n",
    "testing (e.g., using Python's unittest framework).\n",
    "Gained experience with distributed systems concepts relevant to scalable ML applications.\n",
    "SELF-STUDY & KEY LEARNINGS\n",
    "●​●​●​Core Texts: Deep-dived into \"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" (Géron) and \"Pattern\n",
    "Recognition and Machine Learning\" (Bishop).\n",
    "Foundational Knowledge: Solidified understanding through study of 10+ resources covering Linear Algebra, Calculus,\n",
    "Probability & Statistics, and essential Deep Learning concepts.\n",
    "Online Courses: Completed 12+ courses across platforms like Coursera/Udemy covering Python, Data Science\n",
    "methodologies, AWS fundamentals, and MLOps principles (mention specific relevant course names if possible, e.g.,\n",
    "\"Machine Learning by Andrew Ng\").\n",
    "PROJECTS\n",
    "Credit Card Fraud Detection Model (2024)\n",
    "●​\n",
    "●​\n",
    "●​\n",
    "●​\n",
    "Developed a Support Vector Machine (SVM) model to predict credit card fraud, achieving 94% accuracy.\n",
    "Reduced feature engineering time by 20% through optimized data preprocessing with Pandas and NumPy.\n",
    "Improved model performance by 10% through hyperparameter tuning with GridSearchCV.\n",
    "Presented model insights with clear visualizations (Matplotlib, Seaborn), reducing report analysis time by 15%.\n",
    "Bookstore Sales Data Analysis & Visualization | University Project (2024 – 2025)\n",
    "●​●​Analyzed a dataset of 10,000+ book records and sales transactions using Python (Pandas) and SQLite to uncover\n",
    "purchasing patterns and customer segments.\n",
    "Implemented Recency-Frequency-Monetary (RFM) analysis to score and segment customers, identifying high-value\n",
    "●​●​●​●​patrons and potential churn risks.\n",
    "Optimized SQL queries and Pandas data manipulation techniques, achieving a 30% reduction in data processing and\n",
    "analysis time.\n",
    "Developed interactive data visualizations (bar charts, scatter plots) using Matplotlib and Seaborn to illustrate sales\n",
    "trends, top-performing genres, and RFM segment distributions.\n",
    "Created a custom GUI application using Tkinter to present key findings and analytical insights, improving data\n",
    "accessibility for non-technical users by 20%.\n",
    "Generated reports that informed potential sales strategies, contributing to a projected 15% increase in targeted\n",
    "marketing effectiveness based on data insights.\n",
    "Smart Gate IoT System (Data Handling Focus) | University Project (2023 – 2024)\n",
    "●​●​●​Contributed to an IoT project involving automated vehicle detection and data collection using sensors and servos.\n",
    "Implemented data handling logic to process and store sensor readings (1000+ entries per day) reliably using Python and\n",
    "Firebase cloud storage.\n",
    "Assisted in integrating mobile camera detection for real-time data input, focusing on data validation and error handling\n",
    "aspects.\n",
    "TECHNICAL SKILLS\n",
    "●​●​●​●​●​●​Machine Learning: Scikit-learn, TensorFlow (Keras), Model Development & Evaluation, Feature Engineering, Data\n",
    "Preprocessing, Hyperparameter Tuning, Classification, Regression, Clustering Basics, NLP Concepts\n",
    "Python Libraries: Pandas, NumPy, Matplotlib, Seaborn, Flask\n",
    "Data Analysis & Visualization: Statistical Analysis, Data Modeling, Power BI, Excel, Google Sheets\n",
    "Databases: SQL (MySQL, PostgreSQL), NoSQL (MongoDB)\n",
    "Software Development: Git, GitHub, REST API Development, Unit Testing\n",
    "Foundations: Statistics & Probability, Linear Algebra, Calculus\n",
    "LANGUAGES\n",
    "●​ Arabic: Native\n",
    "●​ English: Advanced\n",
    "\"\"\"\n",
    "preprocessed_file = '/home/jax/CVreviewArabian/model/preprocessed_jobs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T22:57:05.866403Z",
     "iopub.status.busy": "2025-08-27T22:57:05.866079Z",
     "iopub.status.idle": "2025-08-27T22:57:05.872471Z",
     "shell.execute_reply": "2025-08-27T22:57:05.871690Z",
     "shell.execute_reply.started": "2025-08-27T22:57:05.866380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_skills_from_docs(docs, skills_list):\n",
    "        \"\"\"\n",
    "        Extracts skills from a list of spaCy docs.\n",
    "        \"\"\"\n",
    "        skills_per_doc = []\n",
    "        for doc in docs:\n",
    "            processed_tokens = [\n",
    "                token.lemma_\n",
    "                for token in doc\n",
    "                if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "            ]\n",
    "            text_for_regex = ' '.join(processed_tokens)\n",
    "            found_skills = set()\n",
    "            for skill in skills_list:\n",
    "                pattern = r\"\\b\" + re.escape(skill) + r\"\\b\"\n",
    "                if re.search(pattern, text_for_regex):\n",
    "                    found_skills.add(skill)\n",
    "            skills_per_doc.append(found_skills)\n",
    "        return skills_per_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:17:18.383194Z",
     "iopub.status.busy": "2025-08-27T23:17:18.382371Z",
     "iopub.status.idle": "2025-08-27T23:17:19.003062Z",
     "shell.execute_reply": "2025-08-27T23:17:19.001980Z",
     "shell.execute_reply.started": "2025-08-27T23:17:18.383168Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed job data from /home/jax/CVreviewArabian/model/preprocessed_jobs.pkl...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(preprocessed_file):\n",
    "    print(f\"Loading preprocessed job data from {preprocessed_file}...\")\n",
    "    df2 = pd.read_pickle(preprocessed_file)\n",
    "else:\n",
    "    df2['combined_text'] = df2['Job Description'] + ' ' + df2['skills'] + ' ' + df2['Responsibilities']\n",
    "\n",
    "        # Batch process body texts with progress\n",
    "        # Note: For multiprocessing, tqdm on pipe might not work perfectly; consider setting n_process=1 for accurate progress if needed.\n",
    "        # Alternatively, keep n_process>1 for speed, and add print statements or use multiprocessing-aware progress if advanced setup.\n",
    "    body_texts = df2['combined_text'].str.lower().tolist()\n",
    "    print(\"Processing body texts with spaCy...\")\n",
    "    body_docs = list(tqdm(nlp.pipe(body_texts, batch_size=100, n_process=4), total=len(body_texts), desc=\"spaCy processing body texts\"))  # Progress on generator consumption\n",
    "    df2['body_skills'] = extract_skills_from_docs(body_docs, SKILLS_LIST)\n",
    "\n",
    "    # Batch process title texts (shorter, but still batched for consistency)\n",
    "    title_texts = df2['Job Title'].str.lower().tolist()\n",
    "    print(\"Processing title texts with spaCy...\")\n",
    "    title_docs = list(tqdm(nlp.pipe(title_texts, batch_size=100, n_process=4), total=len(title_texts), desc=\"spaCy processing title texts\"))\n",
    "    df2['title_skills'] = extract_skills_from_docs(title_docs, SKILLS_LIST)\n",
    "\n",
    "    # 3. Combine skills from title and body with progress\n",
    "    tqdm.pandas(desc=\"Combining skills\")\n",
    "    df2['processed_skills'] = df2.progress_apply(lambda row: row['title_skills'] | row['body_skills'], axis=1)\n",
    "\n",
    "    # Save the preprocessed DataFrame for future runs\n",
    "    df2.to_pickle(preprocessed_file)\n",
    "    print(f\"Preprocessed job data saved to {preprocessed_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:18:16.714679Z",
     "iopub.status.busy": "2025-08-27T23:18:16.713809Z",
     "iopub.status.idle": "2025-08-27T23:18:16.720879Z",
     "shell.execute_reply": "2025-08-27T23:18:16.719989Z",
     "shell.execute_reply.started": "2025-08-27T23:18:16.714648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_and_extract_skills(text, skills_list):\n",
    "    \"\"\"\n",
    "    Preprocesses text and extracts a set of skills from it.\n",
    "    - text: The raw text to process (from a job description or CV).\n",
    "    - skills_list: The master list of skills to search for.\n",
    "    \"\"\"\n",
    "    # Create a spaCy doc object\n",
    "    doc = nlp(text.lower())\n",
    "\n",
    "    # 1. Lemmatize tokens and remove stop words and punctuation\n",
    "    processed_tokens = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "    ]\n",
    "\n",
    "    # 2. Extract skills using regex for all skills (simplified to always use regex)\n",
    "    found_skills = set()\n",
    "    text_for_regex = ' '.join(processed_tokens)\n",
    "\n",
    "    for skill in skills_list:\n",
    "        pattern = r\"\\b\" + re.escape(skill) + r\"\\b\"\n",
    "        if re.search(pattern, text_for_regex):\n",
    "            found_skills.add(skill)\n",
    "\n",
    "    return found_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:26:19.233836Z",
     "iopub.status.busy": "2025-08-27T23:26:19.233473Z",
     "iopub.status.idle": "2025-08-27T23:26:19.311410Z",
     "shell.execute_reply": "2025-08-27T23:26:19.310533Z",
     "shell.execute_reply.started": "2025-08-27T23:26:19.233806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Skills extracted from CV ---\n",
      "{'git', 'sql', 'software development', 'python'}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_skills = preprocess_and_extract_skills(cv_text, SKILLS_LIST)\n",
    "\n",
    "print(\"--- Skills extracted from CV ---\")\n",
    "print(candidate_skills)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:26:23.422357Z",
     "iopub.status.busy": "2025-08-27T23:26:23.422030Z",
     "iopub.status.idle": "2025-08-27T23:26:23.758850Z",
     "shell.execute_reply": "2025-08-27T23:26:23.758103Z",
     "shell.execute_reply.started": "2025-08-27T23:26:23.422333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarity scores: 100%|██████████| 161594/161594 [00:00<00:00, 869973.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 3 Job Matches ---\n",
      "                      Job Title  similarity_score\n",
      "1510034  Database Administrator               0.4\n",
      "1142854  Database Administrator               0.4\n",
      "575833   Database Administrator               0.4\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_jaccard_similarity(set1, set2):\n",
    "    \"\"\"Calculates the Jaccard similarity between two sets.\"\"\"\n",
    "    if not set1 and not set2:\n",
    "        return 0.0\n",
    "\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0.0\n",
    "\n",
    "# Compute similarity scores (fast vectorized apply on sets) with progress\n",
    "tqdm.pandas(desc=\"Calculating similarity scores\")\n",
    "df2['similarity_score'] = df2['processed_skills'].progress_apply(\n",
    "    lambda job_skills: calculate_jaccard_similarity(candidate_skills, job_skills)\n",
    ")\n",
    "\n",
    "ranked_jobs = df2.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "print(\"--- Top 3 Job Matches ---\")\n",
    "print(ranked_jobs[['Job Title', 'similarity_score']].head(3))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarity scores for tester roles: 100%|██████████| 4911/4911 [00:00<00:00, 348178.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 3 Job Matches for Software Tester ---\n",
      "          Job Title  similarity_score\n",
      "461143   QA Analyst              0.25\n",
      "1455722  QA Analyst              0.25\n",
      "1095929  QA Analyst              0.25\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_weighted_similarity(cv_skills, job_skills, testing_skills, general_skills):\n",
    "    \"\"\"\n",
    "    Calculates a weighted similarity score, prioritizing testing skills for Software Tester roles.\n",
    "    Testing skills get 2x weight; general skills get 1x weight.\n",
    "    \"\"\"\n",
    "    if not cv_skills and not job_skills:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate intersections for testing and general skills\n",
    "    testing_intersection = len(cv_skills.intersection(job_skills & set(testing_skills)))\n",
    "    general_intersection = len(cv_skills.intersection(job_skills & set(general_skills)))\n",
    "    \n",
    "    # Apply weights: 2 for testing skills, 1 for general skills\n",
    "    weighted_intersection = (2 * testing_intersection) + general_intersection\n",
    "    \n",
    "    # Union of all skills\n",
    "    union = len(cv_skills.union(job_skills))\n",
    "    \n",
    "    return weighted_intersection / union if union != 0 else 0.0\n",
    "\n",
    "# Filter jobs by tester-related keywords in Job Title or Role\n",
    "df2['is_tester_role'] = df2['Job Title'].str.lower().apply(\n",
    "    lambda x: any(keyword in x for keyword in TESTER_KEYWORDS)\n",
    ") | df2['Role'].str.lower().apply(\n",
    "    lambda x: any(keyword in x for keyword in TESTER_KEYWORDS)\n",
    ")\n",
    "\n",
    "# Only process tester-related jobs to reduce computation\n",
    "tester_jobs = df2[df2['is_tester_role']].copy()\n",
    "\n",
    "# Compute similarity scores with progress\n",
    "tqdm.pandas(desc=\"Calculating similarity scores for tester roles\")\n",
    "tester_jobs['similarity_score'] = tester_jobs['processed_skills'].progress_apply(\n",
    "    lambda job_skills: calculate_weighted_similarity(candidate_skills, job_skills, TESTING_SKILLS, GENERAL_SKILLS)\n",
    ")\n",
    "\n",
    "# Sort by similarity score\n",
    "ranked_jobs = tester_jobs.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "print(\"--- Top 3 Job Matches for Software Tester ---\")\n",
    "print(ranked_jobs[['Job Title', 'similarity_score']].head(3))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:35:56.654994Z",
     "iopub.status.busy": "2025-08-27T23:35:56.654167Z",
     "iopub.status.idle": "2025-08-27T23:35:56.661717Z",
     "shell.execute_reply": "2025-08-27T23:35:56.660823Z",
     "shell.execute_reply.started": "2025-08-27T23:35:56.654948Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Skill Gap Analysis for the Top Job: 'QA Analyst' ---\n",
      "Required Skills for this Job: {'python'}\n",
      "Candidate's Skills: {'git', 'sql', 'software development', 'python'}\n",
      "\n",
      "Congratulations! The candidate possesses all the required skills for this role.\n"
     ]
    }
   ],
   "source": [
    "if not ranked_jobs.empty:\n",
    "    best_match = ranked_jobs.iloc[0]\n",
    "    best_match_skills = best_match['processed_skills']\n",
    "\n",
    "    missing_skills = best_match_skills - candidate_skills\n",
    "\n",
    "    print(f\"--- Skill Gap Analysis for the Top Job: '{best_match['Job Title']}' ---\")\n",
    "    print(f\"Required Skills for this Job: {best_match_skills}\")\n",
    "    print(f\"Candidate's Skills: {candidate_skills}\")\n",
    "\n",
    "    if missing_skills:\n",
    "        print(f\"\\nMissing Skills to learn for this role: {missing_skills}\")\n",
    "    else:\n",
    "        print(\"\\nCongratulations! The candidate possesses all the required skills for this role.\")\n",
    "else:\n",
    "    print(\"No matching jobs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:24:33.809913Z",
     "iopub.status.busy": "2025-08-27T23:24:33.809554Z",
     "iopub.status.idle": "2025-08-27T23:24:33.837152Z",
     "shell.execute_reply": "2025-08-27T23:24:33.836326Z",
     "shell.execute_reply.started": "2025-08-27T23:24:33.809887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Title\n",
       "UX/UI Designer                  4855\n",
       "Digital Marketing Specialist    2797\n",
       "Software Engineer               2763\n",
       "Network Engineer                2439\n",
       "Software Tester                 2095\n",
       "                                ... \n",
       "QA Engineer                      344\n",
       "Personal Assistant               344\n",
       "Procurement Coordinator          342\n",
       "Key Account Manager              341\n",
       "Inventory Analyst                334\n",
       "Name: count, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Job Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:32:42.882779Z",
     "iopub.status.busy": "2025-08-27T23:32:42.882398Z",
     "iopub.status.idle": "2025-08-27T23:32:43.326251Z",
     "shell.execute_reply": "2025-08-27T23:32:43.325340Z",
     "shell.execute_reply.started": "2025-08-27T23:32:42.882731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'communication',\n",
       " 'critical thinking',\n",
       " 'data analysis',\n",
       " 'power bi',\n",
       " 'python',\n",
       " 'tableau'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['processed_skills'].iloc[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sets_to_lists(dictionary):\n",
    "    return {key: list(value) for key, value in dictionary.items()}\n",
    "\n",
    "# Function to convert lists back to sets after loading JSON\n",
    "def convert_lists_to_sets(dictionary):\n",
    "    return {key: set(value) for key, value in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file = \"skillsModel1.json\"\n",
    "#load json\n",
    "with open(json_file, 'r') as f:\n",
    "        job_skills_dict = convert_lists_to_sets(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job skills dictionary with 147 unique job titles.\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary mapping Job Title to processed_skills\n",
    "job_skills_dict = dict(zip(df2['Job Title'], df2['processed_skills']))\n",
    "print(\"Created job skills dictionary with\", len(job_skills_dict), \"unique job titles.\")\n",
    "with open(json_file, 'w') as f:\n",
    "        json.dump(convert_sets_to_lists(job_skills_dict), f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Speech Therapist': {'communication'},\n",
       " 'Architectural Designer': set(),\n",
       " 'Electrical Engineer': set(),\n",
       " 'Account Manager': {'communication'},\n",
       " 'Purchasing Agent': set(),\n",
       " 'Customer Service Manager': {'leadership'},\n",
       " 'SEM Specialist': set(),\n",
       " 'Nurse Manager': {'communication'},\n",
       " 'Legal Counsel': set(),\n",
       " 'Legal Secretary': set(),\n",
       " 'Electrical Designer': set(),\n",
       " 'Physician Assistant': set(),\n",
       " 'UX/UI Designer': {'adobe xd', 'sketch'},\n",
       " 'Mechanical Engineer': {'system design'},\n",
       " 'Procurement Manager': {'communication'},\n",
       " 'Substance Abuse Counselor': set(),\n",
       " 'Front-End Developer': {'css', 'html', 'javascript'},\n",
       " 'Environmental Engineer': set(),\n",
       " 'Database Administrator': set(),\n",
       " 'Marketing Analyst': {'communication',\n",
       "  'data visualization',\n",
       "  'power bi',\n",
       "  'python',\n",
       "  'sql',\n",
       "  'tableau'},\n",
       " 'Data Entry Clerk': set(),\n",
       " 'Research Analyst': {'communication', 'critical thinking'},\n",
       " 'Quality Assurance Analyst': set(),\n",
       " 'Civil Engineer': set(),\n",
       " 'Systems Administrator': {'mysql', 'sql'},\n",
       " 'Software Engineer': {'communication',\n",
       "  'django',\n",
       "  'java',\n",
       "  'nosql',\n",
       "  'python',\n",
       "  'sql'},\n",
       " 'Environmental Consultant': set(),\n",
       " 'Urban Planner': set(),\n",
       " 'Tax Consultant': {'communication'},\n",
       " 'Marketing Manager': set(),\n",
       " 'Social Media Manager': set(),\n",
       " 'Business Development Manager': set(),\n",
       " 'Marketing Coordinator': set(),\n",
       " 'Art Director': set(),\n",
       " 'Event Coordinator': {'communication', 'creativity'},\n",
       " 'Executive Assistant': {'communication',\n",
       "  'project management',\n",
       "  'time management'},\n",
       " 'Investment Banker': set(),\n",
       " 'Key Account Manager': set(),\n",
       " 'Network Administrator': {'azure', 'communication'},\n",
       " 'Teacher': set(),\n",
       " 'SEO Specialist': set(),\n",
       " 'Nurse Practitioner': set(),\n",
       " 'SEO Analyst': set(),\n",
       " 'Data Engineer': {'sql'},\n",
       " 'Research Scientist': set(),\n",
       " 'HR Coordinator': set(),\n",
       " 'Data Scientist': {'deep learning', 'machine learning', 'python'},\n",
       " 'Psychologist': {'critical thinking'},\n",
       " 'Architect': set(),\n",
       " 'Pediatrician': {'communication'},\n",
       " 'Systems Analyst': set(),\n",
       " 'Supply Chain Manager': set(),\n",
       " 'Software Architect': {'azure', 'docker'},\n",
       " 'Customer Success Manager': {'communication'},\n",
       " 'Operations Manager': {'leadership'},\n",
       " 'Digital Marketing Specialist': set(),\n",
       " 'Occupational Therapist': {'communication'},\n",
       " 'Software Tester': set(),\n",
       " 'Brand Ambassador': {'communication'},\n",
       " 'Administrative Assistant': {'communication',\n",
       "  'data analysis',\n",
       "  'time management'},\n",
       " 'Content Writer': {'creativity'},\n",
       " 'Web Developer': {'angular', 'css', 'html', 'javascript', 'react'},\n",
       " 'Landscape Designer': {'project management'},\n",
       " 'QA Engineer': {'leadership'},\n",
       " 'Physical Therapist': set(),\n",
       " 'Sales Representative': set(),\n",
       " 'Inventory Analyst': set(),\n",
       " 'Family Lawyer': set(),\n",
       " 'Market Research Analyst': set(),\n",
       " 'Legal Assistant': {'communication'},\n",
       " 'Product Designer': {'sketch'},\n",
       " 'Office Manager': set(),\n",
       " 'Financial Controller': set(),\n",
       " 'Procurement Specialist': set(),\n",
       " 'Customer Service Representative': set(),\n",
       " 'Front-End Engineer': {'angular',\n",
       "  'frontend development',\n",
       "  'javascript',\n",
       "  'react'},\n",
       " 'Copywriter': set(),\n",
       " 'Interior Designer': set(),\n",
       " 'Investment Analyst': set(),\n",
       " 'Email Marketing Specialist': {'communication'},\n",
       " 'Litigation Attorney': set(),\n",
       " 'Registered Nurse': set(),\n",
       " 'Sales Manager': set(),\n",
       " 'QA Analyst': set(),\n",
       " 'Aerospace Engineer': set(),\n",
       " 'Mechanical Designer': {'adobe xd', 'communication', 'creativity', 'sketch'},\n",
       " 'Systems Engineer': {'system design'},\n",
       " 'Project Coordinator': {'communication', 'time management'},\n",
       " 'UI Developer': {'css', 'html', 'javascript', 'web development'},\n",
       " 'Graphic Designer': {'communication', 'creativity'},\n",
       " 'Social Media Coordinator': {'adaptability', 'communication', 'creativity'},\n",
       " 'Family Nurse Practitioner': set(),\n",
       " 'Brand Manager': set(),\n",
       " 'Software Developer': {'android', 'java', 'kotlin', 'react', 'swift'},\n",
       " 'Structural Engineer': {'project management'},\n",
       " 'Business Analyst': {'communication'},\n",
       " 'Data Analyst': {'big data',\n",
       "  'hadoop',\n",
       "  'python',\n",
       "  'pytorch',\n",
       "  'spark',\n",
       "  'tensorflow'},\n",
       " 'Landscape Architect': set(),\n",
       " 'Web Designer': {'css', 'html', 'javascript', 'web development'},\n",
       " 'Marketing Specialist': set(),\n",
       " 'Human Resources Manager': set(),\n",
       " 'Java Developer': {'java'},\n",
       " 'Public Relations Specialist': {'communication'},\n",
       " 'Network Engineer': set(),\n",
       " 'Dental Hygienist': set(),\n",
       " 'Financial Advisor': set(),\n",
       " 'Wedding Planner': set(),\n",
       " 'Accountant': set(),\n",
       " 'Network Analyst': set(),\n",
       " 'Account Director': {'communication', 'data analysis'},\n",
       " 'Process Engineer': set(),\n",
       " 'Technical Writer': set(),\n",
       " 'Chemical Engineer': {'project management'},\n",
       " 'HR Manager': set(),\n",
       " 'Pharmaceutical Sales Representative': set(),\n",
       " 'Marketing Director': {'communication'},\n",
       " 'Product Manager': {'agile', 'communication', 'product management'},\n",
       " 'Procurement Coordinator': set(),\n",
       " 'Supply Chain Analyst': set(),\n",
       " 'Network Technician': {'cybersecurity'},\n",
       " 'UX Researcher': set(),\n",
       " 'Social Worker': {'communication'},\n",
       " 'Finance Manager': set(),\n",
       " 'Event Planner': {'communication'},\n",
       " 'Network Security Specialist': {'cybersecurity'},\n",
       " 'IT Administrator': set(),\n",
       " 'Customer Support Specialist': {'communication'},\n",
       " 'Account Executive': set(),\n",
       " 'Back-End Developer': {'communication'},\n",
       " 'Event Manager': set(),\n",
       " 'IT Manager': {'cybersecurity', 'leadership', 'project management'},\n",
       " 'Legal Advisor': set(),\n",
       " 'Database Developer': {'cassandra', 'mongodb', 'nosql'},\n",
       " 'Paralegal': {'communication'},\n",
       " 'Sales Consultant': {'communication'},\n",
       " 'Project Manager': {'communication', 'leadership', 'project management'},\n",
       " 'Chemical Analyst': set(),\n",
       " 'Financial Analyst': set(),\n",
       " 'Art Teacher': {'communication', 'creativity'},\n",
       " 'IT Support Specialist': set(),\n",
       " 'Personal Assistant': {'communication', 'time management'},\n",
       " 'Market Analyst': set(),\n",
       " 'HR Generalist': {'communication'},\n",
       " 'Veterinarian': {'communication'},\n",
       " 'Sales Associate': {'communication'},\n",
       " 'Investment Advisor': {'communication'},\n",
       " 'Financial Planner': {'communication'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_skills_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SCIENCE_SKILLS = [\n",
    "    'python', 'r', 'sql', 'pandas', 'numpy', 'scikit-learn', 'matplotlib', 'seaborn',\n",
    "    'machine learning', 'data analysis', 'data visualization', 'power bi', 'data mining',\n",
    "    'statistical analysis', 'data modeling', 'linear algebra', 'probability', 'cloud computing',\n",
    "    'data science', 'mysql'\n",
    "]\n",
    "GENERAL_SKILLS = [\n",
    "    'java', 'c++', 'git', 'agile', 'scrum', 'problem solving', 'communication',\n",
    "    'software development', 'database', 'excel', 'google sheets'\n",
    "]\n",
    "SKILLS_LIST = DATA_SCIENCE_SKILLS + GENERAL_SKILLS\n",
    "\n",
    "# Role keywords for filtering data science-related jobs\n",
    "DATA_SCIENCE_KEYWORDS = ['data scientist', 'data analyst', 'machine learning engineer', 'data engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Skills extracted from CV ---\n",
      "{'linear algebra', 'mysql', 'matplotlib', 'seaborn', 'data science', 'git', 'statistical analysis', 'probability', 'software development', 'database', 'python', 'power bi', 'excel', 'machine learning', 'numpy', 'sql', 'data analysis'}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_skills(text, skills_list):\n",
    "    \"\"\"\n",
    "    Preprocesses text and extracts a set of skills from it.\n",
    "    \"\"\"\n",
    "    doc = nlp(text.lower())\n",
    "    processed_tokens = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "    ]\n",
    "    text_for_regex = ' '.join(processed_tokens)\n",
    "    found_skills = set()\n",
    "    for skill in skills_list:\n",
    "        pattern = r\"\\b\" + re.escape(skill) + r\"\\b\"\n",
    "        if re.search(pattern, text_for_regex):\n",
    "            found_skills.add(skill)\n",
    "    return found_skills\n",
    "\n",
    "candidate_skills = preprocess_and_extract_skills(cv_text, SKILLS_LIST)\n",
    "\n",
    "print(\"--- Skills extracted from CV ---\")\n",
    "print(candidate_skills)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarity scores: 100%|██████████| 147/147 [00:00<00:00, 495231.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 3 Job Matches for Data Scientist ---\n",
      "        Job Title  similarity_score\n",
      "1  Data Scientist          0.222222\n",
      "0   Data Engineer          0.117647\n",
      "2    Data Analyst          0.090909\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_weighted_similarity(cv_skills, job_skills, data_science_skills, general_skills):\n",
    "    \"\"\"\n",
    "    Calculates a weighted similarity score, prioritizing data science skills.\n",
    "    \"\"\"\n",
    "    if not cv_skills or not job_skills:\n",
    "        return 0.0\n",
    "    data_science_intersection = len(cv_skills.intersection(job_skills & set(data_science_skills)))\n",
    "    general_intersection = len(cv_skills.intersection(job_skills & set(general_skills)))\n",
    "    weighted_intersection = (2 * data_science_intersection) + general_intersection\n",
    "    union = len(cv_skills.union(job_skills))\n",
    "    return weighted_intersection / union if union != 0 else 0.0\n",
    "\n",
    "# Create a DataFrame from job_skills_dict for similarity scoring\n",
    "job_similarity = []\n",
    "for job_title, job_skills in tqdm(job_skills_dict.items(), desc=\"Calculating similarity scores\"):\n",
    "    # Only consider data science-related jobs\n",
    "    if any(keyword in job_title.lower() for keyword in DATA_SCIENCE_KEYWORDS):\n",
    "        similarity = calculate_weighted_similarity(candidate_skills, job_skills, DATA_SCIENCE_SKILLS, GENERAL_SKILLS)\n",
    "        job_similarity.append({'Job Title': job_title, 'similarity_score': similarity, 'job_skills': job_skills})\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "similarity_df = pd.DataFrame(job_similarity)\n",
    "ranked_jobs = similarity_df.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "print(\"--- Top 3 Job Matches for Data Scientist ---\")\n",
    "print(ranked_jobs[['Job Title', 'similarity_score']].head(3))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Skill Gap Analysis for the Top Job: 'Data Scientist' ---\n",
      "Required Skills for this Job: {'machine learning', 'deep learning', 'python'}\n",
      "Candidate's Skills: {'linear algebra', 'mysql', 'matplotlib', 'seaborn', 'data science', 'git', 'statistical analysis', 'probability', 'software development', 'database', 'python', 'power bi', 'excel', 'machine learning', 'numpy', 'sql', 'data analysis'}\n",
      "\n",
      "Missing Skills to learn for this role: {'deep learning'}\n"
     ]
    }
   ],
   "source": [
    "if not ranked_jobs.empty:\n",
    "    best_match = ranked_jobs.iloc[0]\n",
    "    best_match_skills = best_match['job_skills']\n",
    "\n",
    "    missing_skills = best_match_skills - candidate_skills\n",
    "\n",
    "    print(f\"--- Skill Gap Analysis for the Top Job: '{best_match['Job Title']}' ---\")\n",
    "    print(f\"Required Skills for this Job: {best_match_skills}\")\n",
    "    print(f\"Candidate's Skills: {candidate_skills}\")\n",
    "\n",
    "    if missing_skills:\n",
    "        print(f\"\\nMissing Skills to learn for this role: {missing_skills}\")\n",
    "    else:\n",
    "        print(\"\\nCongratulations! The candidate possesses all the required skills for this role.\")\n",
    "else:\n",
    "    print(\"No matching data science jobs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_pickle('/home/jax/CVreviewArabian/model/preprocessed_jobs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Experience', 'Qualifications', 'Salary Range', 'location', 'Country',\n",
       "       'latitude', 'longitude', 'Work Type', 'Company Size', 'Preference',\n",
       "       'Job Title', 'Role', 'Job Portal', 'Job Description', 'Benefits',\n",
       "       'skills', 'Responsibilities', 'combined_text', 'body_skills',\n",
       "       'title_skills', 'processed_skills'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3749643,
     "sourceId": 6488828,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
